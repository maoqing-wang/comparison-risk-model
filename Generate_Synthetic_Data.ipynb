{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O17VwBAJWCQ8",
        "outputId": "a63da772-8234-48ec-824b-272ed1977dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data generation complete. All files are saved as .csv.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Parameter Setting\n",
        "nAssets = 50\n",
        "nDays = 252 * 5\n",
        "nFactors = 6\n",
        "lookback = 60\n",
        "horizons = [1, 5, 21]  # 1d/1w/1m\n",
        "hlabels = ['h1d', 'h1w', 'h1m']\n",
        "\n",
        "baseDate = datetime(2020, 1, 1)\n",
        "dates = pd.date_range(baseDate, periods=nDays, freq='D')\n",
        "assetIDs = [f\"Asset{i+1}\" for i in range(nAssets)]\n",
        "\n",
        "# 2. Step 1: Simulate returns\n",
        "dailySigma = 0.02\n",
        "returns = dailySigma * np.random.randn(nDays, nAssets)\n",
        "returns_df = pd.DataFrame(returns, index=dates, columns=assetIDs)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "returns_df.to_csv('data/returns.csv')\n",
        "# Date and AssetID can be stored separately.\n",
        "pd.DataFrame({'dates': dates}).to_csv('data/dates.csv', index=False)\n",
        "pd.DataFrame({'assetIDs': assetIDs}).to_csv('data/assetIDs.csv', index=False)\n",
        "\n",
        "# 3. Step 2: Shared artefacts\n",
        "os.makedirs('shared', exist_ok=True)\n",
        "alpha = 0.05 * np.random.randn(nAssets)\n",
        "pd.Series(alpha, index=assetIDs).to_csv('shared/alpha_vector.csv', header=['alpha'])\n",
        "\n",
        "constraints = pd.DataFrame({\n",
        "    'Rebalance': ['Monthly'],\n",
        "    'MaxGrossExposure': [1.0],\n",
        "    'LongOnly': [True],\n",
        "    'TurnoverLimit': [0.25]\n",
        "})\n",
        "constraints.to_csv('shared/constraints.csv', index=False)\n",
        "\n",
        "horizonLabels = pd.DataFrame({'horizonLabels': ['1d', '1w', '1m'], 'horizons': horizons})\n",
        "horizonLabels.to_csv('shared/horizon_map.csv', index=False)\n",
        "\n",
        "# 4. Step 3: Build two factor models\n",
        "for model_name in ['modelA', 'modelB']:\n",
        "    mdlDir = os.path.join('models', model_name)\n",
        "    os.makedirs(mdlDir, exist_ok=True)\n",
        "\n",
        "    # 3a. Exposures\n",
        "    X = np.random.randn(nAssets, nFactors)\n",
        "    X = (X - X.mean()) / X.std()\n",
        "    X_df = pd.DataFrame(X, index=assetIDs, columns=[f\"Factor{j+1}\" for j in range(nFactors)])\n",
        "    X_df.to_csv(os.path.join(mdlDir, 'exposures_X.csv'))\n",
        "\n",
        "    # 3b. Factor returns & residuals\n",
        "    pinvXX = np.linalg.pinv(X.T @ X) @ X.T\n",
        "    factorRets = (pinvXX @ returns.T).T  # nDays × nFactors\n",
        "    factorRets_df = pd.DataFrame(factorRets, index=dates, columns=[f\"Factor{j+1}\" for j in range(nFactors)])\n",
        "    factorRets_df.to_csv(os.path.join(mdlDir, 'factor_returns.csv'))\n",
        "\n",
        "    residuals = returns - (X @ factorRets.T).T  # nDays × nAssets\n",
        "    residuals_df = pd.DataFrame(residuals, index=dates, columns=assetIDs)\n",
        "    residuals_df.to_csv(os.path.join(mdlDir, 'residuals.csv'))\n",
        "\n",
        "    # 3c. Rolling estimates\n",
        "    nH = len(horizons)\n",
        "    sigma_dict = {hlabel: [] for hlabel in hlabels}\n",
        "    F_list, Delta_list = [], []\n",
        "\n",
        "    omega_dir = os.path.join(mdlDir, 'omega')\n",
        "    os.makedirs(omega_dir, exist_ok=True)\n",
        "\n",
        "    for t in range(lookback, nDays):\n",
        "        idx = np.arange(t-lookback, t)\n",
        "        F_win = np.cov(factorRets[idx, :], rowvar=False)\n",
        "        Delta_win = np.var(residuals[idx, :], axis=0)\n",
        "        F_list.append(F_win.flatten())\n",
        "        Delta_list.append(Delta_win)\n",
        "\n",
        "        # asset covariance\n",
        "        omega_t = X @ F_win @ X.T + np.diag(Delta_win)\n",
        "        omega_df = pd.DataFrame(omega_t, index=assetIDs, columns=assetIDs)\n",
        "        omega_df.to_csv(os.path.join(omega_dir, f'omega_{dates[t].strftime(\"%Y%m%d\")}.csv'))\n",
        "\n",
        "        # volatility forecasts for each horizon (per asset)\n",
        "        assetVars = np.diag(omega_t)\n",
        "        for h, hlabel in zip(horizons, hlabels):\n",
        "            sigmas = np.sqrt(h * assetVars)\n",
        "            sigma_dict[hlabel].append(sigmas)\n",
        "\n",
        "    # Save sigma forecasts as DataFrames\n",
        "    for hlabel in hlabels:\n",
        "        sigmas_array = np.array(sigma_dict[hlabel])\n",
        "        idx_dates = dates[lookback:]\n",
        "        sigma_df = pd.DataFrame(sigmas_array, index=idx_dates, columns=assetIDs)\n",
        "        sigma_df.to_csv(os.path.join(mdlDir, f'sigma_forecast_{hlabel}.csv'))\n",
        "\n",
        "    # Save rolling F and Delta as DataFrame\n",
        "    F_df = pd.DataFrame(F_list, index=dates[lookback:])\n",
        "    Delta_df = pd.DataFrame(Delta_list, index=dates[lookback:], columns=assetIDs)\n",
        "    F_df.to_csv(os.path.join(mdlDir, 'F_rolling.csv'))\n",
        "    Delta_df.to_csv(os.path.join(mdlDir, 'Delta_rolling.csv'))\n",
        "\n",
        "print(\"Synthetic data generation complete. All files are saved as .csv.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('synthetic_data', 'zip', '.')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('synthetic_data.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DoYUKbtvWNRF",
        "outputId": "d44fe6f3-fa7d-42be-e3b6-a97eefbda181"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3b5bae1-b224-4615-9db7-2577c5ea7583\", \"synthetic_data.zip\", 63418254)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgSeLvriWmKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}